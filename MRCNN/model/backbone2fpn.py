import tensorflow.keras.models as KM
import tensorflow.keras.layers as KL

from . import Resnet

class Backbone2FPN(KM.Model):
    def __init__(self, config) -> None:
        super().__init__()
        self.config = config
        self.backbone = Resnet(config.BACKBONE)
        
        # Top-down Layers
        # TODO: add assert to varify feature map sizes match what's in config
        self.fpn_c5p5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c5p5')
        self.bn1 = KL.BatchNormalization()
        self.fpn_c4p4 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c4p4')
        self.bn2 = KL.BatchNormalization()
        self.fpn_c3p3 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c3p3')
        self.bn3 = KL.BatchNormalization()
        self.fpn_c2p2 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c2p2')
        self.bn4 = KL.BatchNormalization()
        # Attach 3x3 conv to all P layers to get the final feature maps.
        self.fpn_p2 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p2")
        self.bn5 = KL.BatchNormalization()
        self.fpn_p3 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p3")
        self.bn6 = KL.BatchNormalization()
        self.fpn_p4 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p4")
        self.bn7 = KL.BatchNormalization()
        self.fpn_p5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p5")
        self.bn8 = KL.BatchNormalization()
    
    def call(self, input_feature):
        _, C2, C3, C4, C5 = self.backbone(input_feature, training=self.config.TRAIN_BN)

        # Top-down Layers
        # TODO: add assert to varify feature map sizes match what's in config
        P5 = KL.ReLU()(self.bn1(self.fpn_c5p5(C5)))
        P4 = KL.Add(name="fpn_p4add")([ KL.UpSampling2D(size=(2, 2), name="fpn_p5upsampled")(P5),
                                        KL.ReLU()(self.bn2(self.fpn_c4p4(C4)))])
        P3 = KL.Add(name="fpn_p3add")([ KL.UpSampling2D(size=(2, 2), name="fpn_p4upsampled")(P4),
                                        KL.ReLU()(self.bn3(self.fpn_c3p3(C3)))])
        P2 = KL.Add(name="fpn_p2add")([ KL.UpSampling2D(size=(2, 2), name="fpn_p3upsampled")(P3),
                                        KL.ReLU()(self.bn4(self.fpn_c2p2(C2)))])
        # Attach 3x3 conv to all P layers to get the final feature maps.
        P2 = KL.ReLU()(self.bn5(self.fpn_p2(P2)))
        P3 = KL.ReLU()(self.bn6(self.fpn_p3(P3)))
        P4 = KL.ReLU()(self.bn7(self.fpn_p4(P4)))
        P5 = KL.ReLU()(self.bn8(self.fpn_p5(P5)))
        # P6 is used for the 5th anchor scale in RPN. Generated by
        # subsampling from P5 with stride of 2.
        P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)

        return [C5, P2, P3, P4, P5, P6]
